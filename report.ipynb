{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# 2021 AI/ML 개발 신입(석/박사) 공채 Vision Part 과제\n",
    "\n",
    "\n",
    "# 과제설명\n",
    "\n",
    "# 개요\n",
    "* Classfication 모델 구현 과제\n",
    "    * 해당 과제는 크게 두 가지 Task로 나누어 진행됩니다.\n",
    "    * 각 Task에 명시된 데이터 셋을 사용하여 과제를 수행하고 양식에 따라 결과를 제출합니다.\n",
    "        * `vision.zip` 구성\n",
    "            * `images/` 이미지 파일 폴더\n",
    "            * `task#_(train,test).csv` 데이터셋\n",
    "            * `report.ipynb` jupyter notebook (과제 설명 및 레포트 양식 포함)\n",
    "\n",
    "## Task1\n",
    "\n",
    "### Lightweight classfication 모델 구현\n",
    "주어신 데이터셋을 분류하는 모델을 구현하세요.\n",
    "\n",
    "* Dataset\n",
    "    * `task1_train.csv`: 학습 데이터\n",
    "    * `task1_test.csv`: 평가 데이터\n",
    "    * Format: (Image file name),(Predicted Label)\n",
    "* 평가 항목: \n",
    "    * Accuracy\n",
    "    * 연산량 및 파라미터 수\n",
    "\n",
    "단, 구현 모델은 다음 제약조건을 준수하여야 합니다.\n",
    "* 연산량: **30 MFLOPs 이하** \n",
    "    * convolution, linear 등 주요 layer만 계산 가능\n",
    "    * 계산 방법 설명 필요\n",
    "* 파라미터 수: **2 MB 이하** \n",
    "    * numpy.float32 기준이나 다른 data type 적용 가능\n",
    "* Loss function: **Cross Entropy 사용**\n",
    "* **ML framework 및 data analysis용 library 사용 금지, numpy 사용 가능**\n",
    "    * TensorFlow, PyTorch, JAX, SciPy, scikit-learn, pandas 등 사용 금지\n",
    "    * Utility library 사용 가능\n",
    "\n",
    "\n",
    "## Task2\n",
    "\n",
    "### Robust classfication 모델 구현\n",
    "\n",
    "다음 reference를 참고하여 새로운 데이터셋을 분류하는 모델을 구현하세요.\n",
    "* Symmetric Cross Entropy Loss (https://arxiv.org/pdf/1908.06112.pdf)\n",
    "* Improved Mean Absolute Error (https://arxiv.org/pdf/1903.12141v6.pdf)\n",
    "* Barrier Hinge Loss (https://arxiv.org/pdf/1901.09314.pdf)\n",
    "\n",
    "\n",
    "* Dataset\n",
    "    * `task2_train.csv`: 학습 데이터\n",
    "    * `task2_test.csv`: 평가 데이터\n",
    "    * Format: (Image file name),(Predicted Label)\n",
    "* 평가 항목: \n",
    "    * Accuracy\n",
    "    * 연산량 및 파라미터 수\n",
    "  \n",
    "단, 구현 모델은 다음 제약조건을 준수하여야 합니다.\n",
    "* 연산량: **30 MFLOPs 이하** \n",
    "    * convolution, linear 등 주요 layer만 포함하여 계산 가능\n",
    "    * 계산 방법 설명 필요\n",
    "* 파라미터 수: **2 MB 이하** \n",
    "    * numpy.float32 기준이나 다른 data type 적용 가능\n",
    "* Loss function: **제약 없음**\n",
    "* **ML framework 및 data analysis용 library 사용 금지, numpy 사용 가능**\n",
    "    * TensorFlow, PyTorch, JAX, SciPy, scikit-learn, pandas 등 사용 금지\n",
    "    * Utility library 사용 가능\n",
    "\n",
    "\n",
    "# 제출항목\n",
    "* 구현 코드\n",
    "    * 코드 내 주석 및 모듈화 필수\n",
    "* 평가 데이터에 대한 분류 결과 파일\n",
    "    * `$PROJECT_ROOT/task1_result.csv`, `$PROJECT_ROOT/task2_result.csv`\n",
    "    * Format: (Image file name),(Predicted Label)\n",
    "        * `test.csv` 참조\n",
    "* 과제에 대한 레포트 jupyter notebook \n",
    "    * `$PROJECT_ROOT/report.ipynb`\n",
    "    * 주어진 양식을 활용하여 작성\n",
    "    * 필요 프레임워크 등의 코드는 따로 작성 후 학습 결과만 첨부하거나, 노트북 내에서 학습 진행 가능\n",
    "    * 레포트 항목을 시각화하기 위한 라이브러리 제한은 없음\n",
    "    * 설명을 위해 셀이 추가적으로 필요한 경우 자유롭게 작성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Task1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 결과\n",
    "\n",
    "* 작성 코드에 대한 설명과 실행방법을 정리해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nML framework를 이용하지 않고 ResNet 기반의 모델을 구현하여 주어진 데이터셋에 대해 학습, 평가, 및 추론하였습니다.\\n\\n각각의 코드에 대하여 설명드리겠습니다.\\n\\n\\n- dataloader.py\\n\\n학습을 위해 주어진 csv 파일을 읽고, 이미지 폴더로부터 batch 단위로 데이터를 불러오는 코드입니다.\\n\\n데이터를 전부 학습하면 reset()을 통해 데이터셋을 셔플하고 처음부터 다시 불러옵니다.\\n\\n\\n- evaluate.py\\n\\n평가를 위해 테스트용 csv 파일을 읽고, 이미지로부터 결과를 추출하여 정답과 비교하는 코드입니다.\\n\\n결과에 대한 전체 정확도 및 카테고리 별 정확도를 반환합니다.\\n\\n평가를 통해 정확도가 가장 높은 모델만 저장하게 됩니다.\\n\\n\\n- inference.py\\n\\n학습된 모델을 불러와서 테스트 데이터셋에 대한 결과를 추론하는 코드입니다.\\n\\n이미지 폴더, 테스트 데이터셋에 대한 정보가 담긴 csv 파일, label mapping을 위한 카테고리 파일, 모델 파일, 결과 csv 파일을 저장할 위치, batch 크기를 인자로 받습니다.\\n\\n아래와 같은 형식으로 코드를 실행하면, 추론 결과를 save_pth에 저장하며 정확도를 출력해줍니다.\\n\\npython inference.py --image_dir='/vision/images/' --csv_pth='/vision/task1_test.csv' --category_pth='category_task1.txt' --model_pth='savedmodel/task1' --save_pth='../task1_result.csv' --batch_size=20\\n\\n=> Total accuracy : 80.604\\n=> Class 'Watches' accuracy :  96.850\\n=> Class 'Shoes' accuracy :  98.400\\n...\\n\\n- layer.py\\n\\n모델을 구성하는 여러 layer들에 대한 코드입니다.\\n\\nFully-connected, 2D convolution, max pooling, gloval average pooling, batch normalization 및 ReLU 함수로 구성되어 있습니다.\\n\\n각 layer에 대한 forward, backward 연산을 통해 output을 전달하고 kernel 및 gradient를 업데이트 해주었습니다.\\n\\nFully-connected 와 2D convolution layer의 파라미터는 He uniform initialization 방법을 통해 초기화해주었습니다.\\n\\nFully-connected 와 2D convolution layer는 파라미터를 저장 및 불러올 수 있게 save 및 load 함수를 포함하고 있습니다.\\n\\n\\n- make_category.py\\n\\n학습 데이터를 먼저 읽고 카테고리 맵을 생성하는 코드입니다. 생성한 카테고리 맵을 이용해서 label을 그에 맞는 정수값으로 매핑해줍니다.\\n\\n생성한 카테고리 맵은 저장되어 학습 또는 추론에 이용됩니다.\\n\\n\\n- model.py\\n\\n학습에 사용한 MyResNet 모델에 대한 코드입니다.\\n\\n모델은 ResNet을 기반으로 구현되었으며, 연산량 및 모델 크기에 대한 제한 조건에 맞게 구성되었습니다.\\n\\n모델을 ResBlock들로 구성되었는데, skip-connection을 통해 gradient를 잘 전파할 수 있도록 설계되었습니다.\\n\\n\\n- train.py\\n\\nDataloader를 통해 데이터를 불러오고, Trainer를 통해 모델 학습을 진행하는 코드입니다.\\n\\n학습이 진행됨에 따라 정확도 및 Loss의 크기가 기록되며, 학습된 모델은 정해진 경로에 저장됩니다.\\n\\n이미지 폴더, 학습 및 테스트 데이터셋에 대한 정보가 담긴 csv 파일, label mapping을 위한 카테고리 파일, 모델을 저장할 위치, batch 크기, epoch 수를 인자로 받습니다.\\n\\n아래와 같은 형식으로 코드를 실행하면, 학습이 시작됩니다.\\n\\npython train.py --image_dir='/vision/images/' --train_csv_pth='/vision/task1_train.csv' --test_csv_pth='/vision/task1_test.csv' --category_pth='category_task1.txt' --model_save_pth='savedmodel/task1' --batch_size=20 --epochs=30\\n\\n\\n- trainer.py\\n\\n손실 함수(Cross entropy loss)를 정의하고, backpropagation을 통해 학습을 시작하는 코드입니다.\\n\\n\\n- utils.py\\n\\n학습 및 추론에 필요한 여러가지 함수들을 포함하는 코드입니다.\\n\\n이미지 전처리, 이미지 패딩, csv파일 읽어서 리스트 형태로 변환 등을 포함합니다.\\n\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ML framework를 이용하지 않고 ResNet 기반의 모델을 구현하여 주어진 데이터셋에 대해 학습, 평가, 및 추론하였습니다.\n",
    "\n",
    "각각의 코드에 대하여 설명드리겠습니다.\n",
    "\n",
    "\n",
    "- dataloader.py\n",
    "\n",
    "학습을 위해 주어진 csv 파일을 읽고, 이미지 폴더로부터 batch 단위로 데이터를 불러오는 코드입니다.\n",
    "\n",
    "데이터를 전부 학습하면 reset()을 통해 데이터셋을 셔플하고 처음부터 다시 불러옵니다.\n",
    "\n",
    "\n",
    "- evaluate.py\n",
    "\n",
    "평가를 위해 테스트용 csv 파일을 읽고, 이미지로부터 결과를 추출하여 정답과 비교하는 코드입니다.\n",
    "\n",
    "결과에 대한 전체 정확도 및 카테고리 별 정확도를 반환합니다.\n",
    "\n",
    "평가를 통해 정확도가 가장 높은 모델만 저장하게 됩니다.\n",
    "\n",
    "\n",
    "- inference.py\n",
    "\n",
    "학습된 모델을 불러와서 테스트 데이터셋에 대한 결과를 추론하는 코드입니다.\n",
    "\n",
    "이미지 폴더, 테스트 데이터셋에 대한 정보가 담긴 csv 파일, label mapping을 위한 카테고리 파일, 모델 파일, 결과 csv 파일을 저장할 위치, batch 크기를 인자로 받습니다.\n",
    "\n",
    "image_classification 폴더에서 아래와 같은 형식으로 코드를 실행하면, 추론 결과를 save_pth에 저장하며 정확도를 출력해줍니다.\n",
    "\n",
    "python inference.py --image_dir='/vision/images/' --csv_pth='/vision/task1_test.csv' --category_pth='category_task1.txt' --model_pth='savedmodel/task1' --save_pth='../task1_result.csv' --batch_size=20\n",
    "\n",
    "=> Total accuracy : 80.604\n",
    "=> Class 'Watches' accuracy :  96.850\n",
    "=> Class 'Shoes' accuracy :  98.400\n",
    "...\n",
    "\n",
    "- layer.py\n",
    "\n",
    "모델을 구성하는 여러 layer들에 대한 코드입니다.\n",
    "\n",
    "Fully-connected, 2D convolution, max pooling, gloval average pooling, batch normalization 및 ReLU 함수로 구성되어 있습니다.\n",
    "\n",
    "각 layer에 대한 forward, backward 연산을 통해 output을 전달하고 kernel 및 gradient를 업데이트 해주었습니다.\n",
    "\n",
    "Fully-connected 와 2D convolution layer의 파라미터는 He uniform initialization 방법을 통해 초기화해주었습니다.\n",
    "\n",
    "Fully-connected 와 2D convolution layer는 파라미터를 저장 및 불러올 수 있게 save 및 load 함수를 포함하고 있습니다.\n",
    "\n",
    "\n",
    "- make_category.py\n",
    "\n",
    "학습 데이터를 먼저 읽고 카테고리 맵을 생성하는 코드입니다. 생성한 카테고리 맵을 이용해서 label을 그에 맞는 정수값으로 매핑해줍니다.\n",
    "\n",
    "생성한 카테고리 맵은 저장되어 학습 또는 추론에 이용됩니다.\n",
    "\n",
    "\n",
    "- model.py\n",
    "\n",
    "학습에 사용한 MyResNet 모델에 대한 코드입니다.\n",
    "\n",
    "모델은 ResNet을 기반으로 구현되었으며, 연산량 및 모델 크기에 대한 제한 조건에 맞게 구성되었습니다.\n",
    "\n",
    "모델을 ResBlock들로 구성되었는데, skip-connection을 통해 gradient를 잘 전파할 수 있도록 설계되었습니다.\n",
    "\n",
    "\n",
    "- train.py\n",
    "\n",
    "Dataloader를 통해 데이터를 불러오고, Trainer를 통해 모델 학습을 진행하는 코드입니다.\n",
    "\n",
    "학습이 진행됨에 따라 정확도 및 Loss의 크기가 기록되며, 학습된 모델은 정해진 경로에 저장됩니다.\n",
    "\n",
    "이미지 폴더, 학습 및 테스트 데이터셋에 대한 정보가 담긴 csv 파일, label mapping을 위한 카테고리 파일, 모델을 저장할 위치, batch 크기, epoch 수를 인자로 받습니다.\n",
    "\n",
    "image_classification 폴더에서 아래와 같은 형식으로 코드를 실행하면, 학습이 시작됩니다.\n",
    "\n",
    "python train.py --image_dir='/vision/images/' --train_csv_pth='/vision/task1_train.csv' --test_csv_pth='/vision/task1_test.csv' --category_pth='category_task1.txt' --model_save_pth='savedmodel/task1' --batch_size=20 --epochs=30\n",
    "\n",
    "\n",
    "- trainer.py\n",
    "\n",
    "손실 함수(Cross entropy loss)를 정의하고, backpropagation을 통해 학습을 시작하는 코드입니다.\n",
    "\n",
    "\n",
    "- utils.py\n",
    "\n",
    "학습 및 추론에 필요한 여러가지 함수들을 포함하는 코드입니다.\n",
    "\n",
    "이미지 전처리, 이미지 패딩, csv파일 읽어서 리스트 형태로 변환 등을 포함합니다.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 작성 모델에 관해 설명해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 연산량은 21,923,754 FLOPS 입니다.\n",
      "총 파라미터 크기는 1,408,768 B 입니다.\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "'''\n",
    "- 모델 구조\n",
    "\n",
    "ResNet 기반의 모델을 이용하였습니다.\n",
    "\n",
    "MyResNet은 7x7 Conv2D와 Maxpooling Layer로 이루어진 HeadBlock과 5개의 ResBlock, 그리고 GlobalAveragePooling 및 FullyConnected Layer로 구성되어 있습니다.\n",
    "\n",
    "ResBlock은 3x3 Conv2D - BN Layer - ReLU 가 두 번 연결되어있는 구조를 가집니다.\n",
    "\n",
    "또한 1, 2, 4번째 ResBlock에는, Block의 input tensor을 마지막 BN Layer의 output tensor에 더해주는 skip connection이 있습니다.\n",
    "\n",
    "이 때 input tensor의 차원을 BN Layer의 output tensor에 맞춰주기 위해, skip connection은 하나의 1x1 Conv2D와 BN을 거치게 됩니다.\n",
    "\n",
    "5개의 ResBlock을 거치고 나면, GlobalAveragePooling Layer를 통해 feature의 크기를 1x1로 줄여주고 channel 수만큼의 크기를 가지는 벡터로 변환할 수 있게 됩니다.\n",
    "\n",
    "이후 FullyConnected 및 Softmax Layer를 통해 각 카테고리에 대한 확률분포를 얻게 됩니다.\n",
    "\n",
    "\n",
    "- 모델 크기 및 연산량\n",
    "\n",
    "모델은 총 14개의 Conv2D Layer와 1개의 FullyConnected Layer로 구성되어 있습니다.\n",
    "\n",
    "모델의 입력의 크기를 80x80으로 고정하면, 각 Conv2D Layer의 (커널 크기(정방형), 입력 채널수, 출력 채널수, 출력 크기)는 아래와 같습니다. (sc는 skip connection을 의미합니다.)\n",
    "\n",
    "Conv2D의 경우 파라미터의 수는 (커널 크기 * 입력 채널수 * 출력 채널수)로 결정되며, 연산량은 (커널 크기 * 입력 채널수 * 출력 채널수 * 출력 크기)로 결정됩니다.\n",
    "\n",
    "FullyConnected의 경우 파라미터 수는 (입력 채널수 * 출력 채널수)로 결정되며, 연산량은 ((2*입력 채널수-1) * 출력 채널수)로 결정됩니다.\n",
    "\n",
    "Pooling의 경우 파라미터 수는 0이며, 연산량은 (커널 크기 * 출력 채널 수 * 출력 크기)로 결정됩니다.\n",
    "\n",
    "# Layers\n",
    "conv1(Headblock): (7, 7, 3, 32, 40, 40)  \n",
    "conv2(ResBlock1_1): (3, 3, 32, 32, 20, 20)\n",
    "conv3(ResBlock1_2): (3, 3, 32, 32, 20, 20)\n",
    "conv4(ResBlock1_sc): (1, 1, 32, 32, 20, 20)\n",
    "conv5(ResBlock2_1): (3, 3, 32, 32, 10, 10)\n",
    "conv6(ResBlock2_2): (3, 3, 32, 32, 10, 10)\n",
    "conv7(ResBlock2_sc): (1, 1, 32, 32, 10, 10)\n",
    "conv8(ResBlock3_1): (3, 3, 32, 32, 10, 10)\n",
    "conv9(ResBlock3_2): (3, 3, 32, 32, 10, 10)\n",
    "conv10(ResBlock4_1): (3, 3, 32, 64, 5, 5)\n",
    "conv11(ResBlock4_2): (3, 3, 32, 64, 5, 5)\n",
    "conv12(ResBlock4_sc): (1, 1, 32, 64, 5, 5)\n",
    "conv13(ResBlock5_1): (3, 3, 64, 64, 5, 5)\n",
    "conv14(ResBlock5_2): (3, 3, 64, 64, 5, 5)\n",
    "fully-connected: (64, 22(num_classes of task1))\n",
    "maxpooling: (3, 3, 32, 20, 20)\n",
    "global-averagepooling: (5, 5, 64, 1, 1)\n",
    "\n",
    "Conv2D와 FullyConnect는 He uniform initialization을 통해 초기화하는데, 이 때 사용하는 np.random.uniform 함수의 기본 dtype이 float64입니다.\n",
    "\n",
    "따라서 파라미터는 개당 8Byte를 가지며, 이를 기준으로 총 파라미터 크기를 계산하였습니다.\n",
    "'''\n",
    "\n",
    "dict_layers = {}\n",
    "dict_layers['conv'] = [(7, 7, 3, 32, 40, 40) , (3, 3, 32, 32, 20, 20), (3, 3, 32, 32, 20, 20), (1, 1, 32, 32, 20, 20), (3, 3, 32, 32, 10, 10),\n",
    "                      (3, 3, 32, 32, 10, 10), (1, 1, 32, 32, 10, 10), (3, 3, 32, 32, 10, 10), (3, 3, 32, 32, 10, 10), (3, 3, 32, 64, 5, 5), \n",
    "                      (3, 3, 32, 64, 5, 5), (1, 1, 32, 64, 5, 5), (3, 3, 64, 64, 5, 5), (3, 3, 64, 64, 5, 5)]\n",
    "dict_layers['fc'] = [(64, 22)]\n",
    "dict_layers['pooling'] = [(3, 3, 32, 20, 20), (5, 5, 64, 1, 1)]\n",
    "\n",
    "total_flops, total_params = 0, 0\n",
    "for key in dict_layers.keys():\n",
    "    if key=='conv':\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += layer[0]*layer[1]*layer[2]*layer[3]*layer[4]*layer[5]\n",
    "            total_params += layer[0]*layer[1]*layer[2]*layer[3]\n",
    "    elif key=='fc':\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += (2*layer[0]-1)*layer[1]\n",
    "            total_params += layer[0]*layer[1]\n",
    "    else:\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += layer[0]*layer[1]*layer[2]*layer[3]\n",
    "            \n",
    "print(f'총 연산량은 {total_flops:n} FLOPS 입니다.')\n",
    "print(f'총 파라미터 크기는 {total_params * 8:n} B 입니다.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습 결과를 정리해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습은 약 5epochs 정도 진행했습니다.\n",
    "\n",
    "전체 및 카테고리별 정확도는 아래와 같습니다.\n",
    "\n",
    "=> Total accuracy : 86.135\n",
    "=> Class 'Watches' accuracy :  98.425\n",
    "=> Class 'Shoes' accuracy :  97.600\n",
    "=> Class 'Headwear' accuracy :  74.419\n",
    "=> Class 'Jewellery' accuracy :  88.272\n",
    "=> Class 'Bags' accuracy :  87.773\n",
    "=> Class 'Dress' accuracy :  10.714\n",
    "=> Class 'Fragrance' accuracy :  93.377\n",
    "=> Class 'Saree' accuracy :  90.625\n",
    "=> Class 'Bottomwear' accuracy :  93.052\n",
    "=> Class 'Makeup' accuracy :  6.522\n",
    "=> Class 'Nails' accuracy :  34.694\n",
    "=> Class 'Wallets' accuracy :  88.489\n",
    "=> Class 'Socks' accuracy :  82.692\n",
    "=> Class 'Sandal' accuracy :  56.944\n",
    "=> Class 'Topwear' accuracy :  96.600\n",
    "=> Class 'Flip Flops' accuracy :  66.423\n",
    "=> Class 'Loungewear and Nightwear' accuracy :  21.429\n",
    "=> Class 'Ties' accuracy :  97.368\n",
    "=> Class 'Belts' accuracy :  97.521\n",
    "=> Class 'Lips' accuracy :  87.342\n",
    "=> Class 'Eyewear' accuracy :  100.000\n",
    "=> Class 'Innerwear' accuracy :  84.133\n",
    "\n",
    "\n",
    "테스트 데이터셋에 대한 추론 결과('task1_result.csv')는 아래의 inference 함수를 통해 얻었습니다.\n",
    "\n",
    "python inference.py --image_dir='/vision/images/' --csv_pth='/vision/task1_test.csv' --category_pth='category_task1.txt' --model_pth='savedmodel/task1' --save_pth='../task1_result.csv' --batch_size=20\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open('image_classification/result/accuracy_task1.txt', 'rb') as file:\n",
    "    accuracy = pickle.load(file)\n",
    "with open('image_classification/result/loss_task1.txt', 'rb') as file:\n",
    "    loss = pickle.load(file)\n",
    "steps_loss, losses = [], []\n",
    "for l in loss:\n",
    "    steps_loss.append(l[0])\n",
    "    losses.append(l[1])\n",
    "\n",
    "steps_acc, total_acc = [], []\n",
    "for a in accuracy:\n",
    "    steps_acc.append(a[0])\n",
    "    total_acc.append(a[1])\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('steps')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.plot(steps_loss, losses, color=color)\n",
    "ax1.tick_params(axis='y')\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('total accuracy (%)')  \n",
    "ax2.plot(steps_acc, total_acc, color=color)\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 추가적인 논의사항이 있을 경우 서술해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Task2 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 결과\n",
    "\n",
    "* 작성 코드에 대한 설명과 실행방법을 정리해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(Task1에서 이용한 코드를 기반으로 작성하였습니다.)\n",
    "\n",
    "- trainer.py\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import log_clip\n",
    "from dataloader import *\n",
    "from model import *\n",
    "\n",
    "def log_clip(tensor, A):\n",
    "    tensor[tensor==0] = np.exp(A)\n",
    "    return np.log(tensor)\n",
    "\n",
    "def cross_entropy_loss(pred, label):\n",
    "    batch_size = pred.shape[0]\n",
    "    loss = np.sum(-label * np.log(pred)-(1-label) * np.log(1 - pred))/batch_size\n",
    "    diff = (pred - label)/pred/(1 - pred)/batch_size\n",
    "    return loss, diff\n",
    "\n",
    "def reverse_cross_entropy_loss(pred, label, A):\n",
    "    batch_size = pred.shape[0]\n",
    "    loss = np.sum(-pred * log_clip(label, A)-(1-pred) * log_clip(1-label, A))/batch_size\n",
    "    diff = (log_clip(1 - label, A)-log_clip(label, A))/batch_size\n",
    "    return loss, diff\n",
    "\n",
    "\n",
    "class trainer:\n",
    "    def __init__(self, model, dataset, num_classes, init_lr):\n",
    "        self.dataset = dataset\n",
    "        self.net = model\n",
    "        self.lr = init_lr\n",
    "        self.cls_num = num_classes\n",
    "\n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "    def iterate(self):\n",
    "        images, labels = self.dataset.get_next_batch()\n",
    "\n",
    "        out_tensor = self.net.forward(images)\n",
    "        one_hot_labels = np.eye(self.cls_num)[(labels-1).reshape(-1)].reshape(out_tensor.shape)\n",
    "            \n",
    "        loss, out_diff_tensor = cross_entropy_loss(out_tensor, one_hot_labels)\n",
    "        \n",
    "        self.net.backward(out_diff_tensor, self.lr)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def iterate_symmetric(self, A, a, b):\n",
    "        images, labels = self.dataset.get_next_batch()\n",
    "\n",
    "        out_tensor = self.net.forward(images)\n",
    "        one_hot_labels = np.eye(self.cls_num)[(labels-1).reshape(-1)].reshape(out_tensor.shape)\n",
    "            \n",
    "        ce_loss, ce_out_diff_tensor = cross_entropy_loss(out_tensor, one_hot_labels)\n",
    "        rce_loss, rce_out_diff_tensor = reverse_cross_entropy_loss(out_tensor, one_hot_labels, A)\n",
    "        \n",
    "        total_loss = a*ce_loss + b*rce_loss\n",
    "        out_diff_tensor = a*ce_out_diff_tensor + b*rce_out_diff_tensor\n",
    "        \n",
    "        self.net.backward(out_diff_tensor, self.lr)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "Symmetric Cross Entropy Loss를 정의하였습니다.(https://arxiv.org/pdf/1908.06112.pdf)\n",
    "\n",
    "Noisy label에 tolerant한 Reverse Cross Entropy Loss를 정의함으로써 성능을 높이고, Cross Entropy를 더해줌으로써 수렴에 도움을 주었습니다.\n",
    "\n",
    "One-hot encoding된 label tensor에 log를 바로 취하게 되면 음의 무한으로 발산하기 때문에, 논문에서 제안한 clipping을 구현해서 값이 발산하는 것을 방지하였습니다.\n",
    "\n",
    "또한 Reverse Cross Entropy Loss의 미분값을 계산해서 gradient를 전파해주었습니다.\n",
    "\n",
    "Trainer 부분에서는 iterate_symmetric(self, A, a, b) 함수를 통해 CE loss와 RCE loss를 적절히 더해주었습니다.\n",
    "\n",
    "A, a, b 값은 논문에서 제안한대로 -6, 0.1, 1을 이용하였습니다.\n",
    "\n",
    "Symmetric Learning은 train.py에 --symmetric_training=True 의 인자만 추가해주면 됩니다.\n",
    "\n",
    "python train.py --image_dir='/vision/images/' --train_csv_pth='/vision/task2_train.csv' --test_csv_pth='/vision/task2_test.csv' --category_pth='category_task2.txt' --model_save_pth='savedmodel/task2' --batch_size=20 --epochs=30\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 작성 모델에 관해 설명해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 연산량은 21,923,754 FLOPS 입니다.\n",
      "총 파라미터 크기는 1,408,768 B 입니다.\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "'''\n",
    "(Task1의 모델 설명과 같습니다.)\n",
    "\n",
    "- 모델 구조\n",
    "\n",
    "ResNet 기반의 모델을 이용하였습니다.\n",
    "\n",
    "MyResNet은 7x7 Conv2D와 Maxpooling Layer로 이루어진 HeadBlock과 5개의 ResBlock, 그리고 GlobalAveragePooling 및 FullyConnected Layer로 구성되어 있습니다.\n",
    "\n",
    "ResBlock은 3x3 Conv2D - BN Layer - ReLU 가 두 번 연결되어있는 구조를 가집니다.\n",
    "\n",
    "또한 1, 2, 4번째 ResBlock에는, Block의 input tensor을 마지막 BN Layer의 output tensor에 더해주는 skip connection이 있습니다.\n",
    "\n",
    "이 때 input tensor의 차원을 BN Layer의 output tensor에 맞춰주기 위해, skip connection은 하나의 1x1 Conv2D와 BN을 거치게 됩니다.\n",
    "\n",
    "5개의 ResBlock을 거치고 나면, GlobalAveragePooling Layer를 통해 feature의 크기를 1x1로 줄여주고 channel 수만큼의 크기를 가지는 벡터로 변환할 수 있게 됩니다.\n",
    "\n",
    "이후 FullyConnected 및 Softmax Layer를 통해 각 카테고리에 대한 확률분포를 얻게 됩니다.\n",
    "\n",
    "\n",
    "- 모델 크기 및 연산량\n",
    "\n",
    "모델은 총 14개의 Conv2D Layer와 1개의 FullyConnected Layer로 구성되어 있습니다.\n",
    "\n",
    "모델의 입력의 크기를 80x80으로 고정하면, 각 Conv2D Layer의 (커널 크기(정방형), 입력 채널수, 출력 채널수, 출력 크기)는 아래와 같습니다. (sc는 skip connection을 의미합니다.)\n",
    "\n",
    "Conv2D의 경우 파라미터의 수는 (커널 크기 * 입력 채널수 * 출력 채널수)로 결정되며, 연산량은 (커널 크기 * 입력 채널수 * 출력 채널수 * 출력 크기)로 결정됩니다.\n",
    "\n",
    "FullyConnected의 경우 파라미터 수는 (입력 채널수 * 출력 채널수)로 결정되며, 연산량은 ((2*입력 채널수-1) * 출력 채널수)로 결정됩니다.\n",
    "\n",
    "Pooling의 경우 파라미터 수는 0이며, 연산량은 (커널 크기 * 출력 채널 수 * 출력 크기)로 결정됩니다.\n",
    "\n",
    "# Layers\n",
    "conv1(Headblock): (7, 7, 3, 32, 40, 40)  \n",
    "conv2(ResBlock1_1): (3, 3, 32, 32, 20, 20)\n",
    "conv3(ResBlock1_2): (3, 3, 32, 32, 20, 20)\n",
    "conv4(ResBlock1_sc): (1, 1, 32, 32, 20, 20)\n",
    "conv5(ResBlock2_1): (3, 3, 32, 32, 10, 10)\n",
    "conv6(ResBlock2_2): (3, 3, 32, 32, 10, 10)\n",
    "conv7(ResBlock2_sc): (1, 1, 32, 32, 10, 10)\n",
    "conv8(ResBlock3_1): (3, 3, 32, 32, 10, 10)\n",
    "conv9(ResBlock3_2): (3, 3, 32, 32, 10, 10)\n",
    "conv10(ResBlock4_1): (3, 3, 32, 64, 5, 5)\n",
    "conv11(ResBlock4_2): (3, 3, 32, 64, 5, 5)\n",
    "conv12(ResBlock4_sc): (1, 1, 32, 64, 5, 5)\n",
    "conv13(ResBlock5_1): (3, 3, 64, 64, 5, 5)\n",
    "conv14(ResBlock5_2): (3, 3, 64, 64, 5, 5)\n",
    "fully-connected: (64, 22(num_classes of task1))\n",
    "maxpooling: (3, 3, 32, 20, 20)\n",
    "global-averagepooling: (5, 5, 64, 1, 1)\n",
    "\n",
    "Conv2D와 FullyConnect는 He uniform initialization을 통해 초기화하는데, 이 때 사용하는 np.random.uniform 함수의 기본 dtype이 float64입니다.\n",
    "\n",
    "따라서 파라미터는 개당 8Byte를 가지며, 이를 기준으로 총 파라미터 크기를 계산하였습니다.\n",
    "'''\n",
    "\n",
    "dict_layers = {}\n",
    "dict_layers['conv'] = [(7, 7, 3, 32, 40, 40) , (3, 3, 32, 32, 20, 20), (3, 3, 32, 32, 20, 20), (1, 1, 32, 32, 20, 20), (3, 3, 32, 32, 10, 10),\n",
    "                      (3, 3, 32, 32, 10, 10), (1, 1, 32, 32, 10, 10), (3, 3, 32, 32, 10, 10), (3, 3, 32, 32, 10, 10), (3, 3, 32, 64, 5, 5), \n",
    "                      (3, 3, 32, 64, 5, 5), (1, 1, 32, 64, 5, 5), (3, 3, 64, 64, 5, 5), (3, 3, 64, 64, 5, 5)]\n",
    "dict_layers['fc'] = [(64, 22)]\n",
    "dict_layers['pooling'] = [(3, 3, 32, 20, 20), (5, 5, 64, 1, 1)]\n",
    "\n",
    "total_flops, total_params = 0, 0\n",
    "for key in dict_layers.keys():\n",
    "    if key=='conv':\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += layer[0]*layer[1]*layer[2]*layer[3]*layer[4]*layer[5]\n",
    "            total_params += layer[0]*layer[1]*layer[2]*layer[3]\n",
    "    elif key=='fc':\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += (2*layer[0]-1)*layer[1]\n",
    "            total_params += layer[0]*layer[1]\n",
    "    else:\n",
    "        for layer in dict_layers[key]:\n",
    "            total_flops += layer[0]*layer[1]*layer[2]*layer[3]\n",
    "            \n",
    "print(f'총 연산량은 {total_flops:n} FLOPS 입니다.')\n",
    "print(f'총 파라미터 크기는 {total_params * 8:n} B 입니다.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습 결과를 정리해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습은 약 5epochs 정도 진행했습니다.\n",
    "\n",
    "전체 및 카테고리 별 정확도는 아래와 같습니다.\n",
    "\n",
    "=> Total accuracy : 80.873\n",
    "=> Class 'Watches' accuracy :  96.040\n",
    "=> Class 'Shoes' accuracy :  98.148\n",
    "=> Class 'Headwear' accuracy :  0.000\n",
    "=> Class 'Jewellery' accuracy :  70.690\n",
    "=> Class 'Cufflinks' accuracy :  0.000\n",
    "=> Class 'Apparel Set' accuracy :  0.000\n",
    "=> Class 'Stoles' accuracy :  0.000\n",
    "=> Class 'Bags' accuracy :  95.868\n",
    "=> Class 'Gloves' accuracy :  0.000\n",
    "=> Class 'Dress' accuracy :  0.000\n",
    "=> Class 'Fragrance' accuracy :  77.500\n",
    "=> Class 'Saree' accuracy :  0.000\n",
    "=> Class 'Mufflers' accuracy :  0.000\n",
    "=> Class 'Bottomwear' accuracy :  75.556\n",
    "=> Class 'Makeup' accuracy :  27.273\n",
    "=> Class 'Nails' accuracy :  0.000\n",
    "=> Class 'Wallets' accuracy :  57.500\n",
    "=> Class 'Socks' accuracy :  38.462\n",
    "=> Class 'Sandal' accuracy :  9.677\n",
    "=> Class 'Hair' accuracy :  0.000\n",
    "=> Class 'Topwear' accuracy :  97.893\n",
    "=> Class 'Scarves' accuracy :  0.000\n",
    "=> Class 'Flip Flops' accuracy :  51.429\n",
    "=> Class 'Loungewear and Nightwear' accuracy :  16.667\n",
    "=> Class 'Accessories' accuracy :  0.000\n",
    "=> Class 'Ties' accuracy :  50.000\n",
    "=> Class 'Belts' accuracy :  100.000\n",
    "=> Class 'Eyes' accuracy :  0.000\n",
    "=> Class 'Lips' accuracy :  0.000\n",
    "=> Class 'Eyewear' accuracy :  97.619\n",
    "=> Class 'Skin' accuracy :  0.000\n",
    "=> Class 'Skin Care' accuracy :  0.000\n",
    "=> Class 'Innerwear' accuracy :  51.852\n",
    "\n",
    "테스트 데이터셋에 대한 추론 결과('task2_result.csv')는 아래의 inference 함수를 통해 얻었습니다.\n",
    "\n",
    "python inference.py --image_dir='/vision/images/' --csv_pth='/vision/task2_test.csv' --category_pth='category_task2.txt' --model_pth='savedmodel/task2' --save_pth='../task2_result.csv' --batch_size=20\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with open('image_classification/result/accuracy_task2.txt', 'rb') as file:\n",
    "    accuracy = pickle.load(file)\n",
    "with open('image_classification/result/loss_task2.txt', 'rb') as file:\n",
    "    loss = pickle.load(file)\n",
    "steps_loss, losses = [], []\n",
    "for l in loss:\n",
    "    steps_loss.append(l[0])\n",
    "    losses.append(l[1])\n",
    "\n",
    "steps_acc, total_acc = [], []\n",
    "for a in accuracy:\n",
    "    steps_acc.append(a[0])\n",
    "    total_acc.append(a[1])\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('steps')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.plot(steps_loss, losses, color=color)\n",
    "ax1.tick_params(axis='y')\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('total accuracy (%)')  \n",
    "ax2.plot(steps_acc, total_acc, color=color)\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 추가적인 논의사항이 있을 경우 서술해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( ... )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
   }
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
